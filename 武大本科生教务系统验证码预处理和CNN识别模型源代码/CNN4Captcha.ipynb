{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_loaded\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 65.875 steps, validate on 528 samples\n",
      "Epoch 1/40\n",
      "65/65 [============================>.] - ETA: 0s - loss: 0.3425 - accuracy: 0.9326\n",
      "Epoch 00001: val_loss improved from inf to 0.25283, saving model to captcha_model_.hdf5\n",
      "66/65 [==============================] - 4s 53ms/step - loss: 0.3411 - accuracy: 0.9326 - val_loss: 0.2528 - val_accuracy: 0.9735\n",
      "Epoch 2/40\n",
      "65/65 [============================>.] - ETA: 0s - loss: 0.3161 - accuracy: 0.9388\n",
      "Epoch 00002: val_loss did not improve from 0.25283\n",
      "66/65 [==============================] - 3s 48ms/step - loss: 0.3197 - accuracy: 0.9383 - val_loss: 0.3152 - val_accuracy: 0.9545\n",
      "Epoch 3/40\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3502 - accuracy: 0.9150\n",
      "Epoch 00003: val_loss did not improve from 0.25283\n",
      "66/65 [==============================] - 3s 44ms/step - loss: 0.3492 - accuracy: 0.9151 - val_loss: 0.3026 - val_accuracy: 0.9451\n",
      "Epoch 4/40\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3552 - accuracy: 0.9291\n",
      "Epoch 00004: val_loss did not improve from 0.25283\n",
      "66/65 [==============================] - 3s 45ms/step - loss: 0.3523 - accuracy: 0.9307 - val_loss: 0.2944 - val_accuracy: 0.9640\n",
      "Epoch 5/40\n",
      "65/65 [============================>.] - ETA: 0s - loss: 0.3319 - accuracy: 0.9287\n",
      "Epoch 00005: val_loss did not improve from 0.25283\n",
      "66/65 [==============================] - 3s 44ms/step - loss: 0.3321 - accuracy: 0.9284 - val_loss: 0.3123 - val_accuracy: 0.9394\n",
      "Epoch 6/40\n",
      "65/65 [============================>.] - ETA: 0s - loss: 0.3397 - accuracy: 0.9297\n",
      "Epoch 00006: val_loss did not improve from 0.25283\n",
      "66/65 [==============================] - 3s 46ms/step - loss: 0.3390 - accuracy: 0.9298 - val_loss: 0.2603 - val_accuracy: 0.9697\n",
      "Epoch 7/40\n",
      "65/65 [============================>.] - ETA: 0s - loss: 0.3105 - accuracy: 0.9364\n",
      "Epoch 00007: val_loss improved from 0.25283 to 0.23449, saving model to captcha_model_.hdf5\n",
      "66/65 [==============================] - 3s 49ms/step - loss: 0.3083 - accuracy: 0.9374 - val_loss: 0.2345 - val_accuracy: 0.9811\n",
      "Epoch 8/40\n",
      "65/65 [============================>.] - ETA: 0s - loss: 0.3154 - accuracy: 0.9316\n",
      "Epoch 00008: val_loss did not improve from 0.23449\n",
      "66/65 [==============================] - 3s 47ms/step - loss: 0.3146 - accuracy: 0.9317 - val_loss: 0.2836 - val_accuracy: 0.9489\n",
      "Epoch 9/40\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3283 - accuracy: 0.9331\n",
      "Epoch 00009: val_loss did not improve from 0.23449\n",
      "66/65 [==============================] - 3s 52ms/step - loss: 0.3264 - accuracy: 0.9331 - val_loss: 0.2346 - val_accuracy: 0.9735\n",
      "Epoch 10/40\n",
      "65/65 [============================>.] - ETA: 0s - loss: 0.3431 - accuracy: 0.9220\n",
      "Epoch 00010: val_loss did not improve from 0.23449\n",
      "66/65 [==============================] - 3s 51ms/step - loss: 0.3402 - accuracy: 0.9231 - val_loss: 0.2833 - val_accuracy: 0.9602\n",
      "Epoch 11/40\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3301 - accuracy: 0.9325\n",
      "Epoch 00011: val_loss did not improve from 0.23449\n",
      "66/65 [==============================] - 3s 51ms/step - loss: 0.3344 - accuracy: 0.9322 - val_loss: 0.3044 - val_accuracy: 0.9489\n",
      "Epoch 12/40\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3108 - accuracy: 0.9315\n",
      "Epoch 00012: val_loss did not improve from 0.23449\n",
      "66/65 [==============================] - 3s 45ms/step - loss: 0.3170 - accuracy: 0.9288 - val_loss: 0.2417 - val_accuracy: 0.9735\n",
      "Epoch 13/40\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3118 - accuracy: 0.9344\n",
      "Epoch 00013: val_loss did not improve from 0.23449\n",
      "66/65 [==============================] - 3s 44ms/step - loss: 0.3103 - accuracy: 0.9350 - val_loss: 0.2602 - val_accuracy: 0.9621\n",
      "Epoch 14/40\n",
      "65/65 [============================>.] - ETA: 0s - loss: 0.2944 - accuracy: 0.9446\n",
      "Epoch 00014: val_loss did not improve from 0.23449\n",
      "66/65 [==============================] - 3s 45ms/step - loss: 0.2946 - accuracy: 0.9435 - val_loss: 0.2927 - val_accuracy: 0.9602\n",
      "Epoch 15/40\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2987 - accuracy: 0.9393\n",
      "Epoch 00015: val_loss improved from 0.23449 to 0.22721, saving model to captcha_model_.hdf5\n",
      "66/65 [==============================] - 3s 45ms/step - loss: 0.3003 - accuracy: 0.9393 - val_loss: 0.2272 - val_accuracy: 0.9659\n",
      "Epoch 16/40\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2886 - accuracy: 0.9398 ETA: 1s -\n",
      "Epoch 00016: val_loss did not improve from 0.22721\n",
      "66/65 [==============================] - 3s 51ms/step - loss: 0.2898 - accuracy: 0.9393 - val_loss: 0.2593 - val_accuracy: 0.9716\n",
      "Epoch 17/40\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3026 - accuracy: 0.9414\n",
      "Epoch 00017: val_loss did not improve from 0.22721\n",
      "66/65 [==============================] - 3s 52ms/step - loss: 0.3009 - accuracy: 0.9417 - val_loss: 0.2390 - val_accuracy: 0.9811\n",
      "Epoch 18/40\n",
      "65/65 [============================>.] - ETA: 0s - loss: 0.3007 - accuracy: 0.9374\n",
      "Epoch 00018: val_loss did not improve from 0.22721\n",
      "66/65 [==============================] - 3s 51ms/step - loss: 0.3003 - accuracy: 0.9369 - val_loss: 0.2667 - val_accuracy: 0.9640\n",
      "Epoch 19/40\n",
      "65/65 [============================>.] - ETA: 0s - loss: 0.3087 - accuracy: 0.9317\n",
      "Epoch 00019: val_loss did not improve from 0.22721\n",
      "66/65 [==============================] - 3s 53ms/step - loss: 0.3071 - accuracy: 0.9322 - val_loss: 0.2923 - val_accuracy: 0.9527\n",
      "Epoch 20/40\n",
      "65/65 [============================>.] - ETA: 0s - loss: 0.3325 - accuracy: 0.9263\n",
      "Epoch 00020: val_loss did not improve from 0.22721\n",
      "66/65 [==============================] - 3s 51ms/step - loss: 0.3306 - accuracy: 0.9269 - val_loss: 0.2693 - val_accuracy: 0.9678\n",
      "Epoch 21/40\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2961 - accuracy: 0.9432\n",
      "Epoch 00021: val_loss did not improve from 0.22721\n",
      "66/65 [==============================] - 3s 51ms/step - loss: 0.2998 - accuracy: 0.9417 - val_loss: 0.2473 - val_accuracy: 0.9602\n",
      "Epoch 22/40\n",
      "65/65 [============================>.] - ETA: 0s - loss: 0.2953 - accuracy: 0.9369\n",
      "Epoch 00022: val_loss improved from 0.22721 to 0.21570, saving model to captcha_model_.hdf5\n",
      "66/65 [==============================] - 3s 51ms/step - loss: 0.2969 - accuracy: 0.9369 - val_loss: 0.2157 - val_accuracy: 0.9811\n",
      "Epoch 23/40\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3095 - accuracy: 0.9320\n",
      "Epoch 00023: val_loss did not improve from 0.21570\n",
      "66/65 [==============================] - 3s 51ms/step - loss: 0.3108 - accuracy: 0.9322 - val_loss: 0.2520 - val_accuracy: 0.9716\n",
      "Epoch 24/40\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2886 - accuracy: 0.9379\n",
      "Epoch 00024: val_loss did not improve from 0.21570\n",
      "66/65 [==============================] - 3s 51ms/step - loss: 0.2907 - accuracy: 0.9360 - val_loss: 0.2636 - val_accuracy: 0.9621\n",
      "Epoch 25/40\n",
      "65/65 [============================>.] - ETA: 0s - loss: 0.2954 - accuracy: 0.9374\n",
      "Epoch 00025: val_loss did not improve from 0.21570\n",
      "66/65 [==============================] - 3s 53ms/step - loss: 0.2973 - accuracy: 0.9374 - val_loss: 0.2379 - val_accuracy: 0.9659\n",
      "Epoch 26/40\n",
      "65/65 [============================>.] - ETA: 0s - loss: 0.3077 - accuracy: 0.9335\n",
      "Epoch 00026: val_loss did not improve from 0.21570\n",
      "66/65 [==============================] - 4s 55ms/step - loss: 0.3067 - accuracy: 0.9341 - val_loss: 0.2308 - val_accuracy: 0.9811\n",
      "Epoch 27/40\n",
      "65/65 [============================>.] - ETA: 0s - loss: 0.2929 - accuracy: 0.9403\n",
      "Epoch 00027: val_loss did not improve from 0.21570\n",
      "66/65 [==============================] - 4s 58ms/step - loss: 0.2906 - accuracy: 0.9412 - val_loss: 0.2450 - val_accuracy: 0.9716\n",
      "Epoch 28/40\n",
      "65/65 [============================>.] - ETA: 0s - loss: 0.2770 - accuracy: 0.9412\n",
      "Epoch 00028: val_loss did not improve from 0.21570\n",
      "66/65 [==============================] - 4s 56ms/step - loss: 0.2763 - accuracy: 0.9412 - val_loss: 0.3491 - val_accuracy: 0.9337\n",
      "Epoch 29/40\n",
      "65/65 [============================>.] - ETA: 0s - loss: 0.3196 - accuracy: 0.9258\n",
      "Epoch 00029: val_loss did not improve from 0.21570\n",
      "66/65 [==============================] - 4s 61ms/step - loss: 0.3220 - accuracy: 0.9246 - val_loss: 0.4327 - val_accuracy: 0.9015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/40\n",
      "65/65 [============================>.] - ETA: 0s - loss: 0.3200 - accuracy: 0.9253\n",
      "Epoch 00030: val_loss did not improve from 0.21570\n",
      "66/65 [==============================] - 4s 55ms/step - loss: 0.3182 - accuracy: 0.9265 - val_loss: 0.2318 - val_accuracy: 0.9773\n",
      "Epoch 31/40\n",
      "65/65 [============================>.] - ETA: 0s - loss: 0.2990 - accuracy: 0.9408\n",
      "Epoch 00031: val_loss did not improve from 0.21570\n",
      "66/65 [==============================] - 4s 55ms/step - loss: 0.3002 - accuracy: 0.9402 - val_loss: 0.2568 - val_accuracy: 0.9640\n",
      "Epoch 32/40\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2792 - accuracy: 0.9437\n",
      "Epoch 00032: val_loss did not improve from 0.21570\n",
      "66/65 [==============================] - 4s 54ms/step - loss: 0.2786 - accuracy: 0.9440 - val_loss: 0.2447 - val_accuracy: 0.9621\n",
      "Epoch 33/40\n",
      "65/65 [============================>.] - ETA: 0s - loss: 0.2810 - accuracy: 0.9403\n",
      "Epoch 00033: val_loss did not improve from 0.21570\n",
      "66/65 [==============================] - 4s 55ms/step - loss: 0.2813 - accuracy: 0.9402 - val_loss: 0.2580 - val_accuracy: 0.9678\n",
      "Epoch 34/40\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2788 - accuracy: 0.9408 ETA: 0s - loss: 0.2807 - accuracy: 0.93\n",
      "Epoch 00034: val_loss did not improve from 0.21570\n",
      "66/65 [==============================] - 4s 54ms/step - loss: 0.2796 - accuracy: 0.9417 - val_loss: 0.2334 - val_accuracy: 0.9678\n",
      "Epoch 35/40\n",
      "65/65 [============================>.] - ETA: 0s - loss: 0.2713 - accuracy: 0.9446\n",
      "Epoch 00035: val_loss did not improve from 0.21570\n",
      "66/65 [==============================] - 4s 56ms/step - loss: 0.2711 - accuracy: 0.9440 - val_loss: 0.3105 - val_accuracy: 0.9375\n",
      "Epoch 36/40\n",
      "65/65 [============================>.] - ETA: 0s - loss: 0.3004 - accuracy: 0.9374\n",
      "Epoch 00036: val_loss did not improve from 0.21570\n",
      "66/65 [==============================] - 4s 56ms/step - loss: 0.3016 - accuracy: 0.9374 - val_loss: 0.2884 - val_accuracy: 0.9432\n",
      "Epoch 37/40\n",
      "65/65 [============================>.] - ETA: 0s - loss: 0.2621 - accuracy: 0.9432\n",
      "Epoch 00037: val_loss did not improve from 0.21570\n",
      "66/65 [==============================] - 4s 54ms/step - loss: 0.2611 - accuracy: 0.9440 - val_loss: 0.2558 - val_accuracy: 0.9583\n",
      "Epoch 38/40\n",
      "58/65 [=========================>....] - ETA: 0s - loss: 0.2677 - accuracy: 0.9445"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from helpers import resize_to_fit  \n",
    "\n",
    "# # 不区分大小写的字母文件夹\n",
    "# LETTER_IMAGES_FOLDER = \"extracted_letter_images\"\n",
    "# # 不区分大小写的模型保存位置\n",
    "# MODEL_FILENAME = \"captcha_model.hdf5\"\n",
    "# # 不区分大小写的转换对象保存位置\n",
    "# MODEL_LABELS_FILENAME = \"model_labels.dat\"\n",
    "\n",
    "# # 区分大小写的文件夹\n",
    "LETTER_IMAGES_FOLDER = \"extracted_letter_images_\"\n",
    "# # 区分大小写的模型保存位置\n",
    "MODEL_FILENAME = \"captcha_model_.hdf5\"\n",
    "# # 区分大小写的转换对象保存位置\n",
    "MODEL_LABELS_FILENAME = \"model_labels_.dat\"\n",
    "\n",
    "# initialize the data and labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# 循环输入图像\n",
    "for image_file in paths.list_images(LETTER_IMAGES_FOLDER):   # 1\n",
    "    # 加载图像并将其转换为灰度图像\n",
    "    image = cv2.imread(image_file)                           # 2   \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)          # 3 \n",
    "\n",
    "    # 改变图像大小\n",
    "    image = resize_to_fit(image, 30, 30) # 引入的函数\n",
    "\n",
    "    # A增加一个维度\n",
    "    image = np.expand_dims(image, axis=2)\n",
    "\n",
    "    # 根据字母所在的文件夹来获取字母的名称\n",
    "    label = image_file.split(os.path.sep)[-2]                # 4\n",
    "    if len(label)==2: \n",
    "        label = label[0]\n",
    "   \n",
    "    # 将字母图像及其标签添加到训练数据中\n",
    "    data.append(image)\n",
    "    #print(data)\n",
    "    labels.append(label)\n",
    "\n",
    "# 将原始像素调整为[0，1]范围（这可以改善训练）\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)    \n",
    "    \n",
    "# 分为训练集和测试集\n",
    "(X_train, X_test, Y_train, Y_test) = train_test_split(data, labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# 图像增强\n",
    "image_gen_train = ImageDataGenerator(\n",
    "    rotation_range=45, # 随机45度旋转\n",
    "    height_shift_range=.15, #随机高度偏移 [-0.15,0.15)\n",
    ")\n",
    "\n",
    "\n",
    "# 将标签转换为独热码\n",
    "lb = LabelBinarizer().fit(Y_train) # 构建一个转换对象\n",
    "Y_train = lb.transform(Y_train)\n",
    "Y_test = lb.transform(Y_test)\n",
    "\n",
    "# 保存对象，供以后使用模型解码其预测的含义时使用\n",
    "with open(MODEL_LABELS_FILENAME, \"wb\") as f:\n",
    "    pickle.dump(lb, f)                                      # 5\n",
    "\n",
    "class CNNWhu(keras.Model):\n",
    "    # 搭建神经网络\n",
    "    def __init__(self):\n",
    "        super(CNNWhu, self).__init__()\n",
    "\n",
    "        # 第一个带有最大池化层的卷积层\n",
    "        self.c1 = Conv2D(32, (3, 3), \n",
    "                         padding=\"same\", \n",
    "                         input_shape=(30, 30, 1), \n",
    "                         kernel_regularizer = keras.regularizers.l2(0.01)\n",
    "                         ) # 6 bias_regularizer = keras.regularizers.l2(0.01)\n",
    "        self.b1 = BatchNormalization() # BN层\n",
    "        self.a1 = Activation('relu')\n",
    "        self.p1 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2))\n",
    "        self.d1 = Dropout(0.2)\n",
    "\n",
    "        # 第二个带有最大池化层的卷积层\n",
    "        self.c2 = Conv2D(64, (3, 3), \n",
    "                         padding=\"same\", \n",
    "                         activation=\"relu\" ,\n",
    "                         kernel_regularizer = keras.regularizers.l2(0.01)\n",
    "                         )                 \n",
    "        self.p2 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))\n",
    "\n",
    "        # 第三个卷积层\n",
    "        self.c3 = Conv2D(64, (3, 3), \n",
    "                         padding=\"same\", \n",
    "                         activation=\"relu\",\n",
    "                         kernel_regularizer = keras.regularizers.l2(0.01))\n",
    "\n",
    "        # 压缩层\n",
    "        self.flatten = Flatten()\n",
    "        \n",
    "        # 500个神经元的隐藏层\n",
    "        self.f1 = Dense(500, activation=\"relu\")#  kernel_regularizer=keras.regularizers.l2(0.01)\n",
    "\n",
    "        # 增加Dropout层来避免过拟合\n",
    "        self.d2 = Dropout(0.3)\n",
    "\n",
    "        # 输出层\n",
    "        # model.add(Dense(36, activation=\"softmax\"))\n",
    "        self.f2 = Dense(62, activation=\"softmax\")\n",
    "\n",
    "        \n",
    "    def call(self, x):\n",
    "        x1 = self.c1(x)\n",
    "        x1 = self.b1(x)\n",
    "        x1 = self.a1(x)\n",
    "        x1 = self.p1(x)\n",
    "        x1 = self.d1(x)\n",
    "\n",
    "        x2 = self.c2(x1)\n",
    "        x2 = self.p2(x2)\n",
    "\n",
    "        x3 = self.c3(x2)\n",
    "\n",
    "        y = self.flatten(x3)\n",
    "        y = self.f1(y)\n",
    "        y = self.d2(y)\n",
    "        y = self.f2(y)\n",
    "\n",
    "        return y\n",
    "        \n",
    "model = CNNWhu()\n",
    "\n",
    "# 构建模型\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"]) # 7\n",
    "\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y.%m.%d_%H-%M-%S\")\n",
    "logdir = os.path.join('cnn_callbacks_', current_time)\n",
    "if not os.path.exists(logdir):\n",
    "    os.mkdir(logdir)\n",
    "\n",
    "# 设置断点\n",
    "callbacks = [ModelCheckpoint(MODEL_FILENAME,monitor='val_loss',\n",
    "                             save_weights_only=False, verbose=1, save_best_only=True, period=1)]         \n",
    "\"\"\" # 网络可视化\n",
    "            TensorBoard(log_dir= logdir,histogram_freq=1,\n",
    "                        write_graph=True, write_grads=False, write_images=True,\n",
    "                        embeddings_freq=0, embeddings_layer_names=None,\n",
    "                        embeddings_metadata=None, embeddings_data=None, update_freq=500\n",
    "                        )# tensorboard --logdir=train\n",
    "\"\"\"\n",
    "\n",
    "# 加载断点，训练神经网络\n",
    "\n",
    "if os.path.exists(MODEL_FILENAME):\n",
    "    model = load_model(MODEL_FILENAME)\n",
    "    # 若成功加载前面保存的参数，输出下面的信息\n",
    "    print(\"checkpoint_loaded\")\n",
    "\n",
    "history = model.fit_generator(image_gen_train.flow(X_train, Y_train, batch_size=32),\n",
    "                              validation_data=(X_test, Y_test),\n",
    "                              steps_per_epoch=len(X_train) / 32, epochs=40, \n",
    "                              callbacks = callbacks)# \n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 绘制训练 & 验证的准确率值\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# 绘制训练 & 验证的损失值\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "model.evaluate(X_test, Y_test)\n",
    "\n",
    "# model.save_weights('model_weights.h5')\n",
    "\n",
    "# Save the trained model to disk\n",
    "# model.save(MODEL_FILENAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 列出路径下的文件名或图片名并且存入list列表，进行for循环取出，构建绝对路径即可对该文件进行遍历操作。\n",
    "\n",
    "2. imread函数有两个参数，第一个参数是图片路径，第二个参数表示读取图片的形式，有三种：\n",
    "   cv2.IMREAD_COLOR：加载彩色图片，这个是默认参数，可以直接写1。\n",
    "   cv2.IMREAD_GRAYSCALE：以灰度模式加载图片，可以直接写0。\n",
    "   cv2.IMREAD_UNCHANGED：包括alpha，可以直接写-1\n",
    "\n",
    "3. p1是需要转换的图片，p2是转换成何种格式。\n",
    "   cv2.COLOR_BGR2RGB 将BGR格式转换成RGB格式\n",
    "   cv2.COLOR_BGR2GRAY 将BGR格式转换成灰度图片\n",
    "\n",
    "4. os.path.sep:路径分隔符  linux下是’/’\n",
    "\n",
    "5. 一、dump()方法\n",
    "    pickle.dump(obj, file, [,protocol])\n",
    "    注释：序列化对象，将对象obj保存到文件file中去。参数protocol是序列化模式，默认是0（ASCII协议，表示以文本的形式进行序列化），protocol的值   还可以是1和2（1和2表示以二进制的形式进行序列化。其中，1是老式的二进制协议；2是新二进制协议）。file表示保存到的类文件对象，file必须有       write()接口，file可以是一个以'w'打开的文件或者是一个StringIO对象，也可以是任何可以实现write()接口的对象。\n",
    "   二、load()方法\n",
    "    pickle.load(file)\n",
    "   注释：反序列化对象，将文件中的数据解析为一个python对象。file中有read()接口和readline()接口\n",
    "\n",
    "6. conv2d主要实现了输入张量与设定卷积核的卷积操作\n",
    "    tf.nn.conv2d(\n",
    "    input,  输入\n",
    "    filter,  卷积核\n",
    "    strides,  滑动步长\n",
    "    padding,   图像边沿填充的方式\n",
    "    use_cudnn_on_gpu=True,\n",
    "    data_format='NHWC',\n",
    "    dilations=[1, 1, 1, 1],\n",
    "    name=None\n",
    ")\n",
    "7. - categorical_crossentropy要求target为onehot编码。\n",
    "   - sparse_categorical_crossentropy要求target为非onehot编码，函数内部进行onehot编码实现。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
